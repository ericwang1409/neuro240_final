{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, utils\n",
    "import circuitsvis as cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameter constants\n",
    "N_LAYERS = 1\n",
    "N_HEADS = 1\n",
    "D_MODEL = 32\n",
    "D_HEAD = 32\n",
    "D_MLP = None\n",
    "D_VOCAB = 64\n",
    "SEED = 123\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating lists of a fixed length parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generation\n",
    "import random\n",
    "\n",
    "FIXED_LENGTH = 10\n",
    "\n",
    "def generateLists(n, training=True):\n",
    "    output = []\n",
    "    for _ in range(n):\n",
    "        curr = []\n",
    "        for _ in range(FIXED_LENGTH):\n",
    "            if training:\n",
    "                curr.append(random.randint(0, D_VOCAB - 1))\n",
    "            else:\n",
    "                curr.append(random.randint(D_VOCAB // 2, D_VOCAB - 1))\n",
    "            # curr.append(random.randint(0, 100))\n",
    "\n",
    "        # maximum = max(curr)\n",
    "        # output.append((curr, maximum))\n",
    "        output.append(curr)\n",
    "\n",
    "    output = torch.tensor(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating data function with separate training and testing data so it doesn't see what\n",
    "it's being tested on. Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(n, split=0.7):\n",
    "    output = []\n",
    "    for i in range(D_VOCAB):\n",
    "        for j in range(D_VOCAB):\n",
    "            curr = [i, j]\n",
    "            output.append(curr)\n",
    "\n",
    "    random.shuffle(output)\n",
    "\n",
    "    split_index = int(len(output) * split)\n",
    "    # return training, testing\n",
    "    return torch.tensor(output[:split_index]), torch.tensor(output[split_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_data(data, batch_size=128):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt at cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_generate():\n",
    "    output = []\n",
    "    for i in range(D_VOCAB):\n",
    "        for j in range(D_VOCAB):\n",
    "            curr = [i, j]\n",
    "            output.append(curr)\n",
    "\n",
    "    random.shuffle(output)\n",
    "    return output\n",
    "\n",
    "def cross_val_generate(output, epoch, total_epoch):\n",
    "    testing_size = int(len(output) / total_epoch)\n",
    "    split_index = testing_size * epoch\n",
    "    # return training, testing\n",
    "    testing = torch.tensor(output[split_index:split_index + testing_size])\n",
    "    training = torch.tensor(output[:split_index] + output[split_index + testing_size:])\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating variable length lists without separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateVariableLists(n, training=True):\n",
    "    output = []\n",
    "    for _ in range(n):\n",
    "        i = 0\n",
    "        j = random.randint(0, FIXED_LENGTH)\n",
    "        curr = []\n",
    "        while i < j:\n",
    "            curr.append(random.randint(0, D_VOCAB - 1))\n",
    "            i += 1\n",
    "        while i < FIXED_LENGTH:\n",
    "            curr.append(0)\n",
    "            i += 1\n",
    "        output.append(curr)\n",
    "\n",
    "    output = torch.tensor(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model paramters. We are using one layer, one attention head (which pays to the \n",
    "tokens in contex to another), the dimensions of the model, dimension of the head,\n",
    "vocab is the size of the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model setup\n",
    "cfg = HookedTransformerConfig(\n",
    "    d_model=D_MODEL,\n",
    "    n_layers=N_LAYERS,\n",
    "    n_heads=N_HEADS,\n",
    "    d_head=D_HEAD,\n",
    "    n_ctx=FIXED_LENGTH,\n",
    "    d_vocab=D_VOCAB,\n",
    "    act_fn=\"relu\",\n",
    "    seed=SEED,\n",
    "    device=DEVICE,\n",
    "    attn_only=True\n",
    ")\n",
    "\n",
    "# hooked transformer used for interpretation later\n",
    "model = HookedTransformer(cfg, move_to_device=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(logits, tokens, return_per_token=True, print_tokens=False):\n",
    "    # we take the last element of the logits to make the next prediction\n",
    "    logits = logits[:, -1, :]\n",
    "    answer = torch.max(tokens, dim=1)[0]\n",
    "    log_prob = logits.log_softmax(-1)\n",
    "    if print_tokens:\n",
    "        print(\"tokens\", tokens)\n",
    "        print(\"predicted\", torch.argmax(logits, dim=-1))\n",
    "    # shape is (batch_size, 1) which represents probabilities \n",
    "    # of the correct answer\n",
    "    output_prob = log_prob.gather(-1, answer.unsqueeze(-1))\n",
    "    if return_per_token:\n",
    "        return -1 * output_prob.squeeze()\n",
    "    return -1 * output_prob.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, tokens, return_per_token=False):\n",
    "    logits = logits[:, -1, :]\n",
    "    predicted = torch.argmax(logits, dim=1)\n",
    "    answer = torch.max(tokens, dim=1)[0]\n",
    "    if return_per_token:\n",
    "        return (predicted == answer).float()\n",
    "    return (predicted == answer).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1], [2], [3], [4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, n_epochs, batch_size, batches_per, sequence_length=2):\n",
    "    lr = 1e-3\n",
    "    betas = (0.9, 0.999)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    train_losses = []\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_losses = []\n",
    "        for _ in range(batches_per):\n",
    "            tokens = generateVariableLists(batch_size, training=True)\n",
    "            logits = model(tokens)\n",
    "            # print(tokens.shape)\n",
    "            # print(logits.shape)\n",
    "            losses = loss_function(logits, tokens, print_tokens=False)\n",
    "            losses.mean().backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_losses.extend(losses.detach())\n",
    "\n",
    "        train_losses.append(np.mean(epoch_losses))\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, train loss: {train_losses[-1]}\")\n",
    "\n",
    "    model.eval()\n",
    "    # might want to create the training and testing set beforehand\n",
    "    test_data = generateVariableLists(1280, training=True)\n",
    "    logits = model(test_data)\n",
    "    acc = accuracy(logits, test_data, return_per_token=False)\n",
    "\n",
    "    print(f\"Test accuracy: {acc}\")\n",
    "\n",
    "    return losses\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2(model, n_epochs, batch_size, batches_per, sequence_length=2):\n",
    "    lr = 1e-3\n",
    "    betas = (0.9, 0.999)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    train_losses = []\n",
    "    training_data, testing_data = separate_data(batch_size)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        data_generator = output_data(training_data, batch_size)\n",
    "        epoch_losses = []\n",
    "        for _ in range(batches_per):\n",
    "            tokens = next(data_generator)\n",
    "            logits = model(tokens)\n",
    "            # print(tokens.shape)\n",
    "            # print(logits.shape)\n",
    "            losses = loss_function(logits, tokens, print_tokens=False)\n",
    "            losses.mean().backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_losses.extend(losses.detach())\n",
    "\n",
    "        train_losses.append(np.mean(epoch_losses))\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, train loss: {train_losses[-1]}\")\n",
    "\n",
    "    model.eval()\n",
    "    # might want to create the training and testing set beforehand\n",
    "    logits = model(testing_data)\n",
    "    acc = accuracy(logits, testing_data, return_per_token=False)\n",
    "\n",
    "    print(f\"Test accuracy: {acc}\")\n",
    "\n",
    "    return losses\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, n_epochs, batch_size, batches_per, sequence_length=2):\n",
    "    lr = 1e-3\n",
    "    betas = (0.9, 0.999)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    train_losses = []\n",
    "    all_data = raw_generate()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        tokens, test = cross_val_generate(all_data, epoch, n_epochs - 1)\n",
    "        epoch_losses = []\n",
    "        for _ in range(batches_per):\n",
    "            logits = model(tokens)\n",
    "            # print(tokens.shape)\n",
    "            # print(logits.shape)\n",
    "            losses = loss_function(logits, tokens, print_tokens=False)\n",
    "            losses.mean().backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_losses.extend(losses.detach())\n",
    "\n",
    "        train_losses.append(np.mean(epoch_losses))\n",
    "\n",
    "        model.eval()\n",
    "        logits = model(test)\n",
    "        acc = accuracy(logits, test, return_per_token=False)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, train loss: {train_losses[-1]}\")\n",
    "            print(f\"Test accuracy: {acc}\")\n",
    "\n",
    "    return losses\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, train loss: 4.2221360206604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, train loss: 1.4412012100219727\n",
      "Epoch 20, train loss: 0.38690558075904846\n",
      "Epoch 30, train loss: 0.17430081963539124\n",
      "Epoch 40, train loss: 0.10373319685459137\n",
      "Epoch 50, train loss: 0.07812263071537018\n",
      "Epoch 60, train loss: 0.07083438336849213\n",
      "Epoch 70, train loss: 0.0473560206592083\n",
      "Epoch 80, train loss: 0.03582356497645378\n",
      "Epoch 90, train loss: 0.03998921811580658\n",
      "Test accuracy: 0.996874988079071\n"
     ]
    }
   ],
   "source": [
    "losses = train_model(model, 100, 128, 10, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data, testing_data = separate_data(128)\n",
    "# train_data_gen = output_data(training_data)\n",
    "# tokens = next(train_data_gen)\n",
    "# logits, cache = model.run_with_cache(tokens)\n",
    "\n",
    "tokens = generateVariableLists(128, training=True)\n",
    "logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_pattern = cache[\"pattern\", 0, \"attn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-c39b3d6e-7675\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-c39b3d6e-7675\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23701338469982147, 0.7629866600036621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07710449397563934, 0.060770731419324875, 0.8621248006820679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006418035831302404, 0.001142309745773673, 0.23069967329502106, 0.76173996925354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06777286529541016, 0.05361613631248474, 0.2018638402223587, 0.5675187110900879, 0.10922842472791672, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01736423559486866, 0.010745013132691383, 0.17679709196090698, 0.3595079183578491, 0.40601855516433716, 0.029567211866378784, 0.0, 0.0, 0.0, 0.0], [0.018134120851755142, 0.0254420917481184, 0.16452714800834656, 0.31980249285697937, 0.35145002603530884, 0.039331670850515366, 0.08131246268749237, 0.0, 0.0, 0.0], [0.03786471486091614, 0.07488973438739777, 0.1479114294052124, 0.19452312588691711, 0.3513834774494171, 0.09653637558221817, 0.08661690354347229, 0.010274248197674751, 0.0, 0.0], [0.05519087240099907, 0.15437529981136322, 0.11667460948228836, 0.11150575429201126, 0.2567746639251709, 0.12623558938503265, 0.08831710368394852, 0.05231257155537605, 0.038613609969615936, 0.0], [0.0001351235987385735, 4.1746832721401006e-05, 0.01688557118177414, 0.19928793609142303, 0.7803703546524048, 0.0007130070589482784, 0.002565033035352826, 5.750501372858707e-07, 1.1894022122760362e-07, 6.120185958025104e-07]]], \"tokens\": [\"5\", \"2\", \"20\", \"28\", \"29\", \"15\", \"11\", \"0\", \"0\", \"0\"]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x282684b10>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.attention.attention_heads(tokens=list(map(lambda t: str(t.item()), tokens[0])), attention=attention_pattern[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-01c391db-5318\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-01c391db-5318\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"5\", \"2\", \"20\", \"28\", \"29\", \"15\", \"11\", \"0\", \"0\", \"0\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23701338469982147, 0.7629866600036621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07710449397563934, 0.060770731419324875, 0.8621248006820679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006418035831302404, 0.001142309745773673, 0.23069967329502106, 0.76173996925354, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06777286529541016, 0.05361613631248474, 0.2018638402223587, 0.5675187110900879, 0.10922842472791672, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01736423559486866, 0.010745013132691383, 0.17679709196090698, 0.3595079183578491, 0.40601855516433716, 0.029567211866378784, 0.0, 0.0, 0.0, 0.0], [0.018134120851755142, 0.0254420917481184, 0.16452714800834656, 0.31980249285697937, 0.35145002603530884, 0.039331670850515366, 0.08131246268749237, 0.0, 0.0, 0.0], [0.03786471486091614, 0.07488973438739777, 0.1479114294052124, 0.19452312588691711, 0.3513834774494171, 0.09653637558221817, 0.08661690354347229, 0.010274248197674751, 0.0, 0.0], [0.05519087240099907, 0.15437529981136322, 0.11667460948228836, 0.11150575429201126, 0.2567746639251709, 0.12623558938503265, 0.08831710368394852, 0.05231257155537605, 0.038613609969615936, 0.0], [0.0001351235987385735, 4.1746832721401006e-05, 0.01688557118177414, 0.19928793609142303, 0.7803703546524048, 0.0007130070589482784, 0.002565033035352826, 5.750501372858707e-07, 1.1894022122760362e-07, 6.120185958025104e-07]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x286b1d750>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.attention.attention_patterns(tokens=list(map(lambda t: str(t.item()), tokens[0])), attention=attention_pattern[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-60d8c6d2-c68f\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionHeads } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-60d8c6d2-c68f\",\n",
       "      AttentionHeads,\n",
       "      {\"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5298585891723633, 0.47014138102531433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016971372067928314, 0.014136606827378273, 0.9688920378684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03527383133769035, 0.022286200895905495, 0.1789025515317917, 0.7635374069213867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04655420780181885, 0.04292383790016174, 0.2362651228904724, 0.5024203658103943, 0.17183643579483032, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016337827546522021, 0.0016036033630371094, 0.1038171723484993, 0.8641548752784729, 0.028471702709794044, 0.00031895338906906545, 0.0, 0.0, 0.0, 0.0], [0.0029433169402182102, 0.003550243331119418, 0.12633344531059265, 0.8146095275878906, 0.0487249419093132, 0.0016783729661256075, 0.002160142408683896, 0.0, 0.0, 0.0], [0.0033892581705003977, 0.0038126336876302958, 0.14123395085334778, 0.8133463859558105, 0.03231142461299896, 0.001666737487539649, 0.002636685036122799, 0.0016030087135732174, 0.0, 0.0], [0.09646423906087875, 0.1086631789803505, 0.2399872988462448, 0.23436611890792847, 0.16711477935314178, 0.032751116901636124, 0.04556921869516373, 0.04319809377193451, 0.031885914504528046, 0.0], [2.2358477569373036e-10, 9.704113207442688e-11, 0.00023887913266662508, 0.999758780002594, 2.3979371235327562e-06, 6.784047065430676e-13, 9.12298361854802e-12, 3.690126763183921e-12, 7.632456407342947e-13, 3.927355402694177e-12]]], \"tokens\": [\"1\", \"1\", \"37\", \"53\", \"27\", \"0\", \"0\", \"0\", \"0\", \"0\"]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x105c34bd0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.attention.attention_heads(tokens=list(map(lambda t: str(t.item()), tokens[1])), attention=attention_pattern[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-1f0d19b7-b435\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-1f0d19b7-b435\",\n",
       "      AttentionPatterns,\n",
       "      {\"tokens\": [\"1\", \"1\", \"37\", \"53\", \"27\", \"0\", \"0\", \"0\", \"0\", \"0\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5298585891723633, 0.47014138102531433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016971372067928314, 0.014136606827378273, 0.9688920378684998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03527383133769035, 0.022286200895905495, 0.1789025515317917, 0.7635374069213867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04655420780181885, 0.04292383790016174, 0.2362651228904724, 0.5024203658103943, 0.17183643579483032, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0016337827546522021, 0.0016036033630371094, 0.1038171723484993, 0.8641548752784729, 0.028471702709794044, 0.00031895338906906545, 0.0, 0.0, 0.0, 0.0], [0.0029433169402182102, 0.003550243331119418, 0.12633344531059265, 0.8146095275878906, 0.0487249419093132, 0.0016783729661256075, 0.002160142408683896, 0.0, 0.0, 0.0], [0.0033892581705003977, 0.0038126336876302958, 0.14123395085334778, 0.8133463859558105, 0.03231142461299896, 0.001666737487539649, 0.002636685036122799, 0.0016030087135732174, 0.0, 0.0], [0.09646423906087875, 0.1086631789803505, 0.2399872988462448, 0.23436611890792847, 0.16711477935314178, 0.032751116901636124, 0.04556921869516373, 0.04319809377193451, 0.031885914504528046, 0.0], [2.2358477569373036e-10, 9.704113207442688e-11, 0.00023887913266662508, 0.999758780002594, 2.3979371235327562e-06, 6.784047065430676e-13, 9.12298361854802e-12, 3.690126763183921e-12, 7.632456407342947e-13, 3.927355402694177e-12]]]}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x286af36d0>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.attention.attention_patterns(tokens=list(map(lambda t: str(t.item()), tokens[1])), attention=attention_pattern[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given [x, y] when x is greater than y, then attention pattern of the second one looks at the first one. If y is greater than x, then the second\n",
    "attention pattern looks at the second one. The second position's attention is always focused on the one with the higher token value which makes\n",
    "sense. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
