{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size=64, dim_model=32):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, dim_model)\n",
    "        self.query = nn.Linear(dim_model, dim_model)\n",
    "        self.key = nn.Linear(dim_model, dim_model)\n",
    "        self.value = nn.Linear(dim_model, dim_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim_model, dim_model * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_model * 4, dim_model)\n",
    "        )\n",
    "        self.out = nn.Linear(dim_model, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        attn_weights = F.softmax(q @ k.transpose(-2, -1) / (32 ** 0.5), dim=-1)\n",
    "        attn_output = attn_weights @ v\n",
    "\n",
    "        ffn_output = self.ffn(attn_output + x)\n",
    "\n",
    "        logits = self.out(ffn_output)\n",
    "        return logits\n",
    "\n",
    "model = SimpleTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "FIXED_LENGTH = 3\n",
    "\n",
    "def generateLists(n):\n",
    "    output = []\n",
    "    for _ in range(n):\n",
    "        curr = []\n",
    "        for _ in range(FIXED_LENGTH):\n",
    "            curr.append(random.randint(0, 64 - 1))\n",
    "            # curr.append(random.randint(0, 100))\n",
    "\n",
    "        # maximum = max(curr)\n",
    "        # output.append((curr, maximum))\n",
    "        output.append(curr)\n",
    "\n",
    "    output = torch.tensor(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(n, split=0.7):\n",
    "    output = []\n",
    "    for i in range(64):\n",
    "        for j in range(64):\n",
    "            curr = [i, j]\n",
    "            output.append(curr)\n",
    "\n",
    "    random.shuffle(output)\n",
    "\n",
    "    split_index = int(len(output) * split)\n",
    "    # return training, testing\n",
    "    return torch.tensor(output[:split_index]), torch.tensor(output[split_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_data(data, batch_size=128):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(logits, tokens, return_per_token=True, print_tokens=False):\n",
    "    # we take the last element of the logits to make the next prediction\n",
    "    logits = logits[:, -1, :]\n",
    "    answer = torch.max(tokens, dim=1)[0]\n",
    "    log_prob = logits.log_softmax(-1)\n",
    "    if print_tokens:\n",
    "        print(\"tokens\", tokens)\n",
    "        print(\"predicted\", torch.argmax(logits, dim=-1))\n",
    "    # shape is (batch_size, 1) which represents probabilities \n",
    "    # of the correct answer\n",
    "    output_prob = log_prob.gather(-1, answer.unsqueeze(-1))\n",
    "    if return_per_token:\n",
    "        return -1 * output_prob.squeeze()\n",
    "    return -1 * output_prob.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, tokens, return_per_token=False):\n",
    "    logits = logits[:, -1, :]\n",
    "    predicted = torch.argmax(logits, dim=-1)\n",
    "    answer = torch.max(tokens, dim=1)[0]\n",
    "    # print(predicted, answer)\n",
    "    if return_per_token:\n",
    "        return (predicted == answer).float()\n",
    "    return (predicted == answer).float().mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, n_epochs, batch_size, batches_per, sequence_length=2):\n",
    "    lr = 1e-3\n",
    "    betas = (0.9, 0.999)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "    train_losses = []\n",
    "    training, testing = separate_data(64)\n",
    "    print(training.shape, testing.shape)\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        epoch_losses = []\n",
    "        generator = output_data(training, batch_size)\n",
    "        for _ in range(batches_per):\n",
    "            tokens = next(generator)\n",
    "            logits = model(tokens)\n",
    "            # print(tokens.shape)\n",
    "            # print(logits.shape)\n",
    "            losses = loss_function(logits, tokens, print_tokens=False)\n",
    "            losses.mean().backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            epoch_losses.extend(losses.detach())\n",
    "\n",
    "        train_losses.append(np.mean(epoch_losses))\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, train loss: {train_losses[-1]}\")\n",
    "\n",
    "    model.eval()\n",
    "    logits = model(testing)\n",
    "    acc = accuracy(logits, testing, return_per_token=False)\n",
    "    print(f\"Test accuracy: {acc}\")\n",
    "\n",
    "    return losses\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2867, 2]) torch.Size([1229, 2])\n",
      "Epoch 0, train loss: 1.0200854539871216\n",
      "Epoch 10, train loss: 0.030375253409147263\n",
      "Epoch 20, train loss: 0.005787467118352652\n",
      "Epoch 30, train loss: 0.003140415530651808\n",
      "Epoch 40, train loss: 0.0020687668584287167\n",
      "Epoch 50, train loss: 0.0014912342885509133\n",
      "Epoch 60, train loss: 0.0011353017762303352\n",
      "Epoch 70, train loss: 0.0008969671907834709\n",
      "Epoch 80, train loss: 0.0007281698053702712\n",
      "Epoch 90, train loss: 0.0006035454571247101\n",
      "Epoch 100, train loss: 0.0005086425226181746\n",
      "Epoch 110, train loss: 0.00043434262624941766\n",
      "Epoch 120, train loss: 0.000375020201317966\n",
      "Epoch 130, train loss: 0.00032680280855856836\n",
      "Epoch 140, train loss: 0.00028707709861919284\n",
      "Epoch 150, train loss: 0.0002538898552302271\n",
      "Epoch 160, train loss: 0.00022585768601857126\n",
      "Epoch 170, train loss: 0.00020195622346363962\n",
      "Epoch 180, train loss: 0.00018142335466109216\n",
      "Epoch 190, train loss: 0.00016364110342692584\n",
      "Epoch 200, train loss: 0.00014814028691034764\n",
      "Epoch 210, train loss: 0.00013455563748721033\n",
      "Epoch 220, train loss: 0.00012258009519428015\n",
      "Epoch 230, train loss: 0.00011197740968782455\n",
      "Epoch 240, train loss: 0.00010254285007249564\n",
      "Epoch 250, train loss: 9.411344217369333e-05\n",
      "Epoch 260, train loss: 8.655201236251742e-05\n",
      "Epoch 270, train loss: 7.974733307491988e-05\n",
      "Epoch 280, train loss: 7.359594746958464e-05\n",
      "Epoch 290, train loss: 6.802646385040134e-05\n",
      "Epoch 300, train loss: 6.297036452451721e-05\n",
      "Epoch 310, train loss: 5.836785931023769e-05\n",
      "Epoch 320, train loss: 5.41702211194206e-05\n",
      "Epoch 330, train loss: 5.0333554099779576e-05\n",
      "Epoch 340, train loss: 4.6820750867482275e-05\n",
      "Epoch 350, train loss: 4.3591149733401835e-05\n",
      "Epoch 360, train loss: 4.0614519093651325e-05\n",
      "Epoch 370, train loss: 3.787197056226432e-05\n",
      "Epoch 380, train loss: 3.5345747164683416e-05\n",
      "Epoch 390, train loss: 3.301443575765006e-05\n",
      "Epoch 400, train loss: 3.0858493119012564e-05\n",
      "Epoch 410, train loss: 2.8865650165244006e-05\n",
      "Epoch 420, train loss: 2.7019239496439695e-05\n",
      "Epoch 430, train loss: 2.5309680495411158e-05\n",
      "Epoch 440, train loss: 2.371956179558765e-05\n",
      "Epoch 450, train loss: 2.2239673853619024e-05\n",
      "Epoch 460, train loss: 2.086471431539394e-05\n",
      "Epoch 470, train loss: 1.958611210284289e-05\n",
      "Epoch 480, train loss: 1.8394566723145545e-05\n",
      "Epoch 490, train loss: 1.728085771901533e-05\n",
      "Epoch 500, train loss: 1.6239306205534376e-05\n",
      "Epoch 510, train loss: 1.526907908555586e-05\n",
      "Epoch 520, train loss: 1.4362073670781683e-05\n",
      "Epoch 530, train loss: 1.3512239092960954e-05\n",
      "Epoch 540, train loss: 1.2715757293335628e-05\n",
      "Epoch 550, train loss: 1.1970304512942676e-05\n",
      "Epoch 560, train loss: 1.1270570212218445e-05\n",
      "Epoch 570, train loss: 1.0614881830406375e-05\n",
      "Epoch 580, train loss: 9.999418580264319e-06\n",
      "Epoch 590, train loss: 9.422971743333619e-06\n",
      "Epoch 600, train loss: 8.883308510121424e-06\n",
      "Epoch 610, train loss: 8.371580406674184e-06\n",
      "Epoch 620, train loss: 7.892629582784139e-06\n",
      "Epoch 630, train loss: 7.445155461027753e-06\n",
      "Epoch 640, train loss: 7.020309567451477e-06\n",
      "Epoch 650, train loss: 6.621631655434612e-06\n",
      "Epoch 660, train loss: 6.247909823287046e-06\n",
      "Epoch 670, train loss: 5.895793037780095e-06\n",
      "Epoch 680, train loss: 5.5633254305575974e-06\n",
      "Epoch 690, train loss: 5.25097220815951e-06\n",
      "Epoch 700, train loss: 4.95901394970133e-06\n",
      "Epoch 710, train loss: 4.679347966884961e-06\n",
      "Epoch 720, train loss: 4.417934633238474e-06\n",
      "Epoch 730, train loss: 4.173749857727671e-06\n",
      "Epoch 740, train loss: 3.940274382330244e-06\n",
      "Epoch 750, train loss: 3.72449312635581e-06\n",
      "Epoch 760, train loss: 3.5165344343113247e-06\n",
      "Epoch 770, train loss: 3.323010560052353e-06\n",
      "Epoch 780, train loss: 3.1375889193441253e-06\n",
      "Epoch 790, train loss: 2.9655773232661886e-06\n",
      "Epoch 800, train loss: 2.8019476303597912e-06\n",
      "Epoch 810, train loss: 2.6482825887796935e-06\n",
      "Epoch 820, train loss: 2.501695462342468e-06\n",
      "Epoch 830, train loss: 2.3660040824324824e-06\n",
      "Epoch 840, train loss: 2.234876319562318e-06\n",
      "Epoch 850, train loss: 2.112595439029974e-06\n",
      "Epoch 860, train loss: 1.998975903916289e-06\n",
      "Epoch 870, train loss: 1.8890814317273907e-06\n",
      "Epoch 880, train loss: 1.7854266616268433e-06\n",
      "Epoch 890, train loss: 1.6867076055859798e-06\n",
      "Epoch 900, train loss: 1.5959980146362795e-06\n",
      "Epoch 910, train loss: 1.5078960586834e-06\n",
      "Epoch 920, train loss: 1.4266854577726917e-06\n",
      "Epoch 930, train loss: 1.3496659221345908e-06\n",
      "Epoch 940, train loss: 1.2767441148753278e-06\n",
      "Epoch 950, train loss: 1.2081993645551847e-06\n",
      "Epoch 960, train loss: 1.1417967016313924e-06\n",
      "Epoch 970, train loss: 1.0797709819598822e-06\n",
      "Epoch 980, train loss: 1.0201669056186802e-06\n",
      "Epoch 990, train loss: 9.656848760641878e-07\n",
      "Test accuracy: 0.9178193807601929\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(threshold=10000)\n",
    "losses = train_model(model, 1000, 128, 10, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
